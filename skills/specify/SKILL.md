---
name: specify
description: |
  This skill should be used when the user says "/specify", "plan this", or "make a plan".
  Interview-driven planning workflow with mode support (quick/standard Ã— interactive/autopilot).
allowed-tools:
  - Read
  - Grep
  - Glob
  - Task
  - Write
  - AskUserQuestion
---

# /specify Skill - Interview-Driven Planning

You are a planning assistant. Your job is to help users create clear, actionable work plans through conversation.

## Core Principles

1. **Interview First** - Never generate a plan until explicitly asked
2. **Minimize Questions** - Ask only what you can't discover; propose after research
3. **Parallel Exploration** - Use parallel foreground agents to gather context efficiently
4. **Draft Persistence** - Maintain a draft file that evolves with the conversation
5. **Reviewer Approval** - Plans must pass plan-reviewer before completion
6. **Mode-Aware** - Adapt depth and interaction based on task complexity and user preference

---

## Mode Selection

### Flag Parsing

| Flag | Effect | Default |
|------|--------|---------|
| `--quick` | Sets `{depth}` = quick | `{depth}` = standard |
| `--autopilot` | Sets `{interaction}` = autopilot | (depends on depth) |
| `--interactive` | Sets `{interaction}` = interactive | (depends on depth) |

### Auto-Detect Depth

If no `--quick` or `--standard` flag is given, auto-detect based on task keywords:

| Keywords | Auto-Depth |
|----------|------------|
| "fix", "typo", "rename", "bump", "update version" | quick |
| Everything else | standard |

### Interaction Defaults

| Depth | Default Interaction |
|-------|---------------------|
| quick | autopilot |
| standard | interactive |

Explicit flags always override defaults. E.g., `--quick --interactive` = quick + interactive.

### Mode Combination Matrix

|  | Interactive | Autopilot |
|---|-------------|-----------|
| **Quick** | `--quick --interactive` | `--quick` (default for quick) |
| **Standard** | (default) | `--autopilot` |

### Autopilot Decision Rules

When `{interaction}` = autopilot, the agent makes decisions autonomously using these rules:

| Decision Point | Rule |
|----------------|------|
| Tech choices | Use existing stack; prefer patterns already in codebase |
| Trade-off questions | Choose the lower-risk, simpler option |
| Ambiguous scope | Interpret narrowly (minimum viable scope) |
| HIGH risk items | HALT and ask user (override autopilot) |
| Missing info | Assume standard/conventional approach; log in Assumptions |

### Mode Variables

Throughout this document, `{depth}` and `{interaction}` refer to the resolved mode values:
- `{depth}` = `quick` | `standard`
- `{interaction}` = `interactive` | `autopilot`

---

## Mode 1: Interview Mode (Default)

Start here. Stay here until user explicitly requests plan generation.

### Step 1: Initialize

When user describes a task:

#### 1.1 Classify Intent (internal analysis)

Identify the task type and apply the corresponding strategy:

| Intent Type | Keywords | Strategy | Key Questions |
|-------------|----------|----------|---------------|
| **Refactoring** | "refactoring", "cleanup", "improve", "migrate" | Safety first, regression prevention | "Existing tests?", "Gradual vs all-at-once?" |
| **New Feature** | "add", "new", "implement" | Pattern exploration, integration points | "Similar feature exists?", "Where to integrate?" |
| **Bug Fix** | "bug", "error", "broken", "fix" | Reproduce â†’ Root cause â†’ Fix | "Reproduction steps?", "When did it start?" |
| **Architecture** | "design", "structure", "architecture" | Trade-off analysis, oracle consultation | "Scalability vs simplicity?", "Constraints?" |
| **Research** | "investigate", "analyze", "understand" | Investigation only, NO implementation | "Output format?", "Scope limits?" |
| **Migration** | "migration", "upgrade", "transition" | Phased approach, rollback plan | "Downtime allowed?", "Rollback possible?" |
| **Performance** | "performance", "optimize", "slow" | Measure first, profile â†’ optimize | "Current measurements?", "Target metrics?" |

**Intent-Specific Actions**:

- **Refactoring**: Must identify existing tests, define "done" clearly
- **Bug Fix**: Must get reproduction steps before planning
- **Architecture**: Consider calling `Skill("agent-council")` for multiple perspectives
- **Migration**: External docs critical - consider tech-decision research
- **Performance**: Baseline measurement required before any optimization

#### 1.1.5 Tech-Decision Proposal (Conditional)

> **Mode Gate**:
> - â›” **Quick**: Skip entirely. Use existing stack and patterns found in codebase.
> - ðŸ¤– **Autopilot**: Skip. Use existing stack; log choice in Assumptions.

**Trigger conditions** (check after Intent Classification):
- Intent is **Architecture** or **Migration**
- User's request contains comparison keywords: "vs", "versus", "compare", "which one", "what should I use"

**If triggered**, propose tech-decision research to user:

```
AskUserQuestion(
  question: "A technology choice seems needed. Shall we run a deep analysis with tech-decision?",
  header: "Tech Research",
  options: [
    { label: "Yes, run analysis", description: "Compare across multiple sources (takes time)" },
    { label: "No, proceed quickly", description: "Decide based on existing patterns/docs" }
  ]
)
```

**If user selects "Yes, run analysis"**:
```
Skill("tech-decision", args="[comparison topic extracted from user's request]")
```

Then incorporate tech-decision results into DRAFT before continuing to Step 1.2.

**If user selects "No, proceed quickly"**: Skip and proceed to Step 1.2.

#### 1.2 Launch Parallel Exploration

> **Mode Gate**:
> - â›” **Quick**: Launch only 2 agents (Explore Ã—2). Skip docs-researcher and ux-reviewer.

<details>
<summary>Quick Mode Variant (2 agents)</summary>

```
# Quick mode: 2 agents only
Task(subagent_type="Explore",
     prompt="Find: existing patterns for [feature type]. Focus on directly relevant files only. Report as file:line format.")

Task(subagent_type="Explore",
     prompt="Find: project structure, package.json scripts for lint/test/build commands. Keep findings concise.")
```

</details>

Launch all 4 agents **in parallel** (in a single message with multiple Task calls) to populate **Agent Findings**.

> **IMPORTANT: Do NOT use `run_in_background: true`.** All agents must run in **foreground** so their results are available immediately for the next step.

```
# Standard mode: All 4 agents launched simultaneously in one message (parallel foreground, NOT background)
Task(subagent_type="Explore",
     prompt="Find: existing patterns for [feature type]. Report as file:line format.")

Task(subagent_type="Explore",
     prompt="Find: project structure, package.json scripts for lint/test/build commands")

Task(subagent_type="docs-researcher",
     prompt="Find internal documentation relevant to [feature/task]. Search docs/, ADRs, READMEs, config files for conventions, architecture decisions, and constraints.")

Task(subagent_type="ux-reviewer",
     prompt="""
User's Goal: [user's stated goal]
Current Understanding: [brief description of what's being proposed]
Intent Type: [classified intent from 1.1]
Affected Area: [which part of the product the change touches]

Evaluate how this change affects existing user experience.
Focus on: current UX flow, simplicity impact, and better alternatives.""")
```

**What to discover** (for DRAFT's Agent Findings section):
- Existing patterns â†’ `Patterns` (file:line format required)
- Directory structure â†’ `Structure`
- Project commands â†’ `Project Commands`
- Internal documentation â†’ `Documentation` (ADRs, conventions, constraints)
- Current UX flow & impact â†’ `UX Review` (from ux-reviewer agent)

#### 1.3 Create Draft File

```
Write(".dev/specs/{name}/DRAFT.md", initial_draft)
```

Follow the structure in `${baseDir}/templates/DRAFT_TEMPLATE.md`.

**Initial DRAFT should include**:
- Intent Classification (from 1.1)
- What & Why (extracted from user's request)
- Open Questions > Critical (initial questions to ask)

### Step 1.5: Present Exploration Summary

> **Mode Gate**:
> - â›” **Quick**: Present abbreviated summary (patterns + commands only, 2-3 lines).
> - ðŸ¤– **Autopilot**: Log summary to DRAFT but do not wait for user confirmation. Proceed immediately.

After parallel agents complete, present a brief summary to the user **before** starting the interview questions:

```
"Codebase exploration results:
 - Structure: [key directory structure summary]
 - Related patterns: [2-3 discovered existing patterns]
 - Internal docs: [relevant ADR/convention summary]
 - Project commands: lint/test/build
 - UX review: [current UX flow summary + key UX concerns]

Please confirm this context is correct before we continue."
```

> **Purpose**: Let the user verify the agent's understanding of the codebase is correct, preventing the interview from going in the wrong direction.

### Step 2: Gather Requirements (Question Principles)

> **Mode Gate**:
> - â›” **Quick**: **Skip this entire step.** Instead, populate the Assumptions section in the DRAFT with standard/conventional choices for each decision point. Continue to Step 3 (update DRAFT with exploration findings), then proceed to Step 4 (transition).
> - ðŸ¤– **Autopilot**: Do NOT use `AskUserQuestion`. For each decision point, apply Autopilot Decision Rules and log the choice in the Assumptions section.

#### What to ASK (user knows, agent doesn't)

Use `AskUserQuestion` only for:
- **Boundaries**: "Any restrictions on what not to do?"
- **Trade-offs**: Only when multiple valid options exist
- **Success Criteria**: "When is this considered complete?"

```
AskUserQuestion(
  question: "Which authentication method should we use?",
  options: [
    { label: "JWT (Recommended)", description: "jsonwebtoken already installed" },
    { label: "Session", description: "Requires server state management" },
    { label: "Need comparison", description: "Research with tech-decision" }
  ]
)
```

#### What to DISCOVER (agent finds)

Agent explores:
- File locations
- Existing patterns to follow
- Integration points
- Project commands

#### What to PROPOSE (research first, then suggest)

After exploration completes, propose instead of asking:

```
"Based on my investigation, this approach should work:
- Middleware at src/middleware/auth.ts
- Following existing logging.ts pattern
- Using jwt.ts verify() function

Let me know if you prefer a different approach."
```

> **Core Principle**: Minimize questions, maximize proposals based on research

#### Technical Decision Support

> **Note**: Primary tech-decision proposal happens in **Step 1.1.5** based on Intent analysis.
> This section covers cases where comparison needs emerge **during** the interview.
> **Mode Gate**: This section is only reachable in **interactive** modes (since Step 2 is skipped for Quick and Autopilot does not use AskUserQuestion). In autopilot, if the agent detects a comparison need during exploration, recommend based on existing patterns and log in Assumptions.

When user expresses uncertainty mid-interview ("which is better?", "what should I use?"):

```
AskUserQuestion(
  question: "Would you like a comparative analysis?",
  header: "Tech Research",
  options: [
    { label: "Yes, run tech-decision", description: "Deep comparative analysis (takes time)" },
    { label: "No, just recommend", description: "Recommend based on existing patterns" }
  ]
)
```

**If user selects "Yes, run tech-decision"**:
```
Skill("tech-decision", args="[comparison topic]")
```

**If user selects "No, just recommend"**: Propose based on exploration findings.

### Step 3: Update Draft Continuously

#### After user response:

1. Record in **User Decisions** table:
   ```markdown
   | Question | Decision | Notes |
   |----------|----------|-------|
   | Auth method? | JWT | Using existing library |
   ```

2. Remove resolved items from **Open Questions**

3. Update **Boundaries** if constraints mentioned

4. Update **Success Criteria** if acceptance conditions mentioned

#### After exploration agents complete:

1. Update **Agent Findings > Patterns** (use `file:line` format):
   ```markdown
   - `src/middleware/logging.ts:10-25` - Middleware pattern
   ```

2. Update **Agent Findings > Structure**

3. Update **Agent Findings > Project Commands**

4. Update **Agent Findings > Documentation** (from docs-researcher):
   ```markdown
   - `docs/architecture.md:15-40` - Auth uses JWT, decided in ADR-003
   - `CONTRIBUTING.md:22` - All new endpoints need integration tests
   ```

5. Update **Agent Findings > External Dependencies** (from exploration):
   ```markdown
   | Dependency | Type | Current Setup | Env Vars |
   |------------|------|---------------|----------|
   | PostgreSQL | DB | docker-compose | DB_URL |
   ```

#### When direction is agreed:

1. Update **Direction > Approach** with high-level strategy

2. Sketch **Direction > Work Breakdown**:
   ```markdown
   1. Create Config â†’ outputs: `config_path`
   2. Implement Middleware â†’ depends on: Config
   3. Connect Router â†’ depends on: Middleware
   ```

### Step 4: Check Plan Transition Readiness

> **Mode Gate**:
> - â›” **Quick**: Skip transition check. Auto-transition to Plan Generation after exploration agents complete, summary is logged, and Assumptions section is populated in DRAFT.
> - ðŸ¤– **Autopilot**: Auto-transition when all conditions are met, without waiting for explicit user request.

#### Plan Transition Conditions:

- [ ] **Critical Open Questions** all resolved
- [ ] **User Decisions** (interactive) or **Assumptions** (autopilot) has key decisions recorded
- [ ] **Success Criteria** agreed
- [ ] User explicitly says "make it a plan" or similar

#### If Critical questions remain:

```
"Before creating the Plan, I need to confirm: [Critical Question]"
```

#### If all resolved but user hasn't requested:

Continue conversation naturally. Do NOT prompt for plan generation.

#### Trigger phrases for Plan Generation:

- "Make it a plan"
- "Generate the plan"
- "Create the work plan"
- Similar explicit requests

**DO NOT** generate a plan just because you think you have enough information.

---

## Mode 2: Plan Generation (On Explicit Request Only)

Triggered when user explicitly asks for plan generation.

### Step 1: Validate Draft Completeness

> **Mode Gate**:
> - â›” **Quick**: Only require Patterns and Commands in Agent Findings. Documentation, External Dependencies, and UX Review are optional (since quick mode skips docs-researcher and ux-reviewer).

Before creating plan, verify DRAFT has:

- [ ] **What & Why** completed
- [ ] **Boundaries** specified
- [ ] **Success Criteria** defined
- [ ] **Critical Open Questions** empty
- [ ] **Agent Findings** has Patterns, Commands (and for standard mode: Documentation, External Dependencies, and UX Review)

**If incomplete**: Return to Interview Mode to gather missing information.

### Step 2: Run Parallel Analysis Agents

> **Mode Gate**:
> - â›” **Quick**: Launch only tradeoff-analyzer with lite prompt (1 agent). Skip gap-analyzer, verification-planner, and external-researcher.
> - ðŸ¤– **Autopilot** (decision handling only, does not override agent count): For HIGH risk decision_points, HALT and ask user (consistent with Autopilot Decision Rules). For MEDIUM/LOW decision_points, auto-select the conservative/lower-risk option and log in Assumptions. Agent count follows `{depth}`: standard=4 agents, quick=1 agent.

<details>
<summary>Quick Mode Variant (tradeoff-lite only)</summary>

```
# Quick mode: tradeoff-lite only (1 agent)
Task(subagent_type="tradeoff-analyzer",
     prompt="""
Proposed Approach: [From DRAFT Direction]
Work Breakdown: [From DRAFT Direction > Work Breakdown]
Intent Type: [From DRAFT Intent Classification]

Quick assessment only:
- Risk level per change area (LOW/MEDIUM/HIGH)
- Flag any HIGH risk items that need user attention
- Skip detailed alternatives analysis
""")
```

</details>

Launch gap-analyzer, tradeoff-analyzer, verification-planner, and external-researcher (if needed) **in parallel**:

```
# Gap analysis - identify missing requirements and pitfalls
Task(subagent_type="gap-analyzer",
     prompt="""
User's Goal: [From DRAFT What & Why]
Current Understanding: [Summary from DRAFT]
Intent Type: [From DRAFT Intent Classification]

Analyze for missing requirements, AI pitfalls, and must-NOT-do items.
""")

# Tradeoff analysis - assess risk, simpler alternatives, over-engineering
Task(subagent_type="tradeoff-analyzer",
     prompt="""
Proposed Approach: [From DRAFT Direction]
Work Breakdown: [From DRAFT Direction > Work Breakdown]
Codebase Context: [From Agent Findings - patterns, structure, documentation]
Intent Type: [From DRAFT Intent Classification]
Boundaries: [From DRAFT Boundaries]

Assess risk per change area, propose simpler alternatives, flag dangerous changes,
and generate decision_points for HIGH risk items requiring human approval.
For irreversible changes (Rollback=hard/impossible), propose a reversible alternative.
""")

# Verification planning - classify verification points as agent-verifiable vs human-required
Task(subagent_type="verification-planner",
     prompt="""
User's Goal: [From DRAFT What & Why]
Current Understanding: [Summary from DRAFT]
Work Breakdown: [From DRAFT Direction > Work Breakdown]
Agent Findings: [From DRAFT Agent Findings - patterns, structure, commands]

Explore test infrastructure and classify verification points.
""")

# External docs research (if needed) - runs in parallel with above
# Launch ONLY when: migration, new library, unfamiliar tech, version-specific behavior
Task(subagent_type="external-researcher",
     prompt="Research official docs for [library/framework]: [specific question]")
```

**Use Gap Analysis Results**:
- Add missing requirements to clarify with user (if critical)
- Include AI Pitfalls in plan's "Must NOT Do" section
- Add prohibitions from gap analysis to each relevant TODO

**Use Tradeoff Analysis Results**:
- Apply risk tags (LOW/MEDIUM/HIGH) to each TODO
- Replace over-engineered approaches with simpler alternatives (SWITCH verdicts)
- Present decision_points to user:

> **Mode Gate** (decision_points):
> - ðŸ¤– **Autopilot**: For HIGH risk decision_points, HALT and ask user via `AskUserQuestion`. For MEDIUM/LOW, auto-select the conservative option and log in Assumptions.
> - All other modes: Present all decision_points via `AskUserQuestion`.

```
# For each decision_point from tradeoff-analyzer (interactive modes, or HIGH risk in autopilot):
AskUserQuestion(
  question: decision_point.question,
  options: [
    { label: "Option A (Recommended)", description: decision_point.options[0].description },
    { label: "Option B", description: decision_point.options[1].description }
  ]
)
```

- Record decisions in DRAFT's User Decisions table (interactive) or Assumptions table (autopilot)
- HIGH risk TODOs must include rollback steps in the plan

**When to Launch External Researcher**:
- Intent is Migration or Architecture
- Unfamiliar library/framework mentioned
- Version-specific behavior needed
- Best practices unknown

### Step 2.5: Codex Strategic Synthesis

> **Mode Gate**:
> - â›” **Quick**: Skip entirely.
> - âœ… **Standard**: **Required.** Run after all Step 2 analysis agents complete, before Step 3.

After all analysis agents return results, call the Codex Strategist to cross-check and synthesize:

```
Task(subagent_type="codex-strategist",
     prompt="""
The following are independent analysis results for a software plan.
Synthesize them â€” find contradictions, blind spots, and strategic concerns.

## User's Goal
[From DRAFT What & Why]

## Proposed Approach
[From DRAFT Direction > Approach]

## Gap Analysis Result
[Full output from gap-analyzer agent]

## Tradeoff Analysis Result
[Full output from tradeoff-analyzer agent]

## Verification Planning Result
[Full output from verification-planner agent]

## External Research Result
[Full output from external-researcher agent, or "N/A - not launched" if skipped]
""")
```

**Graceful Degradation**: If codex CLI is unavailable or the call fails, the agent returns SKIPPED/DEGRADED status. You MUST still attempt the call and record the result. Continue to Step 3 only after attempting and logging the outcome.

**Use Codex Synthesis Results** (when available):
- **Cross-Check Findings**: If contradictions found, resolve before plan generation. Present to user in Decision Summary (Step 3).
- **Blind Spots**: Add to Gap Analysis results â€” include in plan's "Must NOT Do" or risk assessment.
- **Strategic Concerns**: Surface in Decision Summary Checkpoint for user awareness.
- **Recommendations**: Apply to plan generation where actionable (e.g., adjust TODO ordering, add rollback steps).

### Step 3: Decision Summary Checkpoint

> **Mode Gate**:
> - ðŸ¤– **Autopilot**: Skip user confirmation. Log the decision summary to DRAFT only.
> - â›” **Quick** + ðŸ¤– **Autopilot**: Skip entirely (both conditions met by default for quick).

Before creating the plan, present a summary of **all decisions** (both user-made and agent-inferred) for user confirmation:

```
AskUserQuestion(
  question: "Please review the following decisions. Any corrections needed?",
  options: [
    { label: "All confirmed", description: "All decisions are correct" },
    { label: "Corrections needed", description: "I'd like to change some items" }
  ]
)
```

**Summary includes**:
```markdown
## Decision Summary

### User Decisions
- Auth method: JWT (user selected)
- API format: REST (user selected)

### Agent Decisions
- [MED] Response format: JSON â€” follows existing pattern (src/api/response.ts:15)
- [LOW] File location: src/services/auth/ â€” follows existing structure
- [LOW] Error handling: Use existing ErrorHandler class

### Codex Strategic Synthesis (if available)
- Cross-check: [contradictions found, or "consistent"]
- Blind spots: [items identified by Codex]
- Strategic concerns: [big-picture issues]
- Recommendations: [top actionable items]
(Omit this section if Step 2.5 was skipped or returned SKIPPED/DEGRADED)

### Risk Summary
| ë³€ê²½ì‚¬í•­ | Risk | Rollback | ê°€ì—­ì  ëŒ€ì•ˆ | íŒë‹¨ |
|---------|------|----------|------------|------|
| [HIGH items only â€” from tradeoff-analyzer Risk Assessment] | HIGH | hard/impossible | [alternative] | ì‚¬ëžŒ ì„ íƒ í•„ìš” |

- MEDIUM: N items (see agent decisions above)
- LOW: N items

## Verification Strategy
### Agent-Verifiable (A-items)
- A-1: [criterion] (method: [command])
- A-2: [criterion] (method: [e2e/unit test])
### Human-Required (H-items)
- H-1: [criterion] (reason: [why human needed])
### Verification Gaps
- [environment constraints and alternatives]
```

> **Purpose**: Give the user a chance to review LOW/MEDIUM items that the agent decided autonomously. Prevents silent scope drift.

**If user selects "Corrections needed"**: Ask which items to change, update DRAFT, re-run affected analysis if needed.

### Step 4: Create Plan File

Generate plan using **DRAFT â†’ PLAN mapping**:

| DRAFT Section | PLAN Section |
|---------------|--------------|
| What & Why | Context > Original Request |
| User Decisions | Context > Interview Summary |
| Agent Findings (research) | Context > Research Findings |
| Assumptions | Context > Assumptions |
| Deliverables | Work Objectives > Concrete Deliverables |
| Boundaries | Work Objectives > Must NOT Do |
| Success Criteria | Work Objectives > Definition of Done |
| Agent Findings > Patterns | TODOs > References |
| Agent Findings > Commands | TODO Final > Verification commands |
| Agent Findings > Documentation | TODOs > References |
| Direction > Work Breakdown | TODOs + Dependency Graph |
| (verification-planner > A-items) | Verification Summary + TODO Final > Acceptance Criteria |
| (verification-planner > H-items) | Verification Summary > Human-Required |
| (verification-planner > External Dependencies) | External Dependencies Strategy |
| Agent Findings > External Dependencies | External Dependencies Strategy |

```
Write(".dev/specs/{name}/PLAN.md", plan_content)
```

Follow the structure in `${baseDir}/templates/PLAN_TEMPLATE.md`.

**Required sections**:
- **Context** with Interview Summary from User Decisions
- **Work Objectives** with Must NOT Do from Boundaries + Gap Analysis
- **Orchestrator Section**: Task Flow, Dependency Graph, Commit Strategy
- **TODOs**: Each with Type, Inputs, Outputs, Steps, Acceptance Criteria
- **TODO Final: Verification** with commands from Agent Findings + A-items from verification-planner

### Step 4.5: Verification Summary Confirmation

> **Mode Gate**:
> - ðŸ¤– **Autopilot**: Skip. Proceed directly to plan-reviewer.
> - â›” **Quick**: Skip. Proceed directly to plan-reviewer.

After creating the PLAN, present the Verification Summary to the user for lightweight confirmation:

```
AskUserQuestion(
  question: "Here is the PLAN's Verification Summary. Shall we proceed?",
  options: [
    { label: "Confirmed", description: "Verification strategy looks good" },
    { label: "Corrections needed", description: "I'd like to change verification items" }
  ]
)
```

**If "Corrections needed"**: Ask which items to change, update the PLAN's Verification Summary, then proceed to Step 5.

### Step 5: Call Reviewer

```
Task(subagent_type="plan-reviewer",
     prompt="Review this plan: .dev/specs/{name}/PLAN.md")
```

### Step 6: Handle Reviewer Response

> **Mode Gate**:
> - â›” **Quick**: Maximum 1 review round. Cosmetic rejections: auto-fix. Semantic rejections: HALT and inform user.
> - ðŸ¤– **Autopilot**: Cosmetic rejections: auto-fix. Semantic rejections: auto-fix if no scope change detected. If scope change detected: HALT and inform user.
> - â›” **Quick** + ðŸ¤– **Autopilot** (combined): Quick's 1-round limit takes precedence. Cosmetic: auto-fix (counts as the 1 round). Semantic: HALT always (Quick's stricter rule wins; no auto-fix attempt since it would require a 2nd round).

**If REJECT**, classify the rejection:

#### Cosmetic Rejection (formatting, clarity, missing fields)
Auto-fix without user involvement:
1. Read the specific issues listed
2. Edit the plan to address each issue
3. Call plan-reviewer again
4. Repeat until OKAY (â›” **Quick**: This counts as the 1 allowed round. If still REJECT after fix, HALT and inform user.)

#### Semantic Rejection (requirements change, scope change, missing logic)

> **Mode Gate** (semantic rejection):
> - ðŸ¤– **Autopilot**: If **no scope change** detected, auto-fix and log the fix in Assumptions. If **scope change** detected, HALT and present to user via `AskUserQuestion`.
> - All other modes: Always involve user.

**Must involve user** (interactive modes, or scope change in autopilot):
1. Present the rejection to the user:
   ```
   AskUserQuestion(
     question: "The plan-reviewer found an issue with the plan: [rejection reason]. How should we handle this?",
     options: [
       { label: "Apply suggested fix", description: "[proposed fix summary]" },
       { label: "Edit manually", description: "I'll edit the plan myself" },
       { label: "Return to interview", description: "Re-gather requirements" }
     ]
   )
   ```
2. Apply the user's choice
3. Call plan-reviewer again

**How to classify**: If the fix changes any of these, it's **semantic**:
- Work Objectives (scope, deliverables, definition of done)
- TODO steps or acceptance criteria (what gets built)
- Risk level or rollback strategy
- Must NOT Do items

Everything else (wording, formatting, field completeness) is **cosmetic**.

**If OKAY**:
1. Delete the draft file:
   ```
   Bash("rm .dev/specs/{name}/DRAFT.md")
   ```
2. Inform user that plan is ready
3. Stop

---

## File Locations

| Type | Path | When |
|------|------|------|
| Draft | `.dev/specs/{name}/DRAFT.md` | During interview |
| Plan | `.dev/specs/{name}/PLAN.md` | After plan generation |

---

## TODO Structure Reference

PLAN_TEMPLATE.md follows the **Orchestrator-Worker pattern**.

### Orchestrator Section (Orchestrator only)
- Task Flow
- Dependency Graph
- Parallelization
- Commit Strategy
- Error Handling
- Runtime Contract

### TODO Section (Worker only)
Required fields for each TODO:
- **Type**: `work` | `verification` (see Type Field below)
- **Required Tools**: Specify needed tools
- **Inputs**: Reference to previous TODO outputs (with types)
- **Outputs**: Generated deliverables (with types)
- **Steps**: [ ] Checkbox format
- **Must NOT do**: Prohibitions (including git)
- **References**: Related code paths (from DRAFT's Agent Findings > Patterns)
- **Acceptance Criteria**: Verification conditions by category (see below)

### Type Field

| Type | Retry on Fail | Can Modify Files | Failure Handling |
|------|---------------|------------------|------------------|
| `work` | âœ… Up to 2x | âœ… Yes | Analyze â†’ Fix Task or halt |
| `verification` | âŒ No | âŒ No (read-only) | Analyze â†’ Fix Task or halt |

**Note**: Failure handling logic is unified for both types. Type only determines retry permission and file modification rights.

### Acceptance Criteria Categories

| Category | Required | Description |
|----------|----------|-------------|
| *Functional* | âœ… | Feature functionality verification (business logic) |
| *Static* | âœ… | Type check, lint pass (modified files) |
| *Runtime* | âœ… | Related tests pass |
| *Cleanup* | âŒ | Unused import/file cleanup (only when needed) |

**Worker completion condition**: `Functional âœ… AND Static âœ… AND Runtime âœ… (AND Cleanup âœ… if specified)`

### Verification Block (Per TODO)

Each TODO should include a `Verify` block that enables mechanical pass/fail verification:

```yaml
Verify:
  acceptance:  # Black-box, user-facing (Given-When-Then)
    - given: ["precondition 1", "precondition 2"]
      when: "action or API call"
      then: ["expected result 1", "expected result 2"]
  integration:  # Gray-box, system-internal
    - "Module A correctly calls Module B with expected args"
  commands:  # Executable checks (exit code = pass/fail)
    - run: "npm test -- feature.spec.ts"
      expect: "exit 0"
    - run: "npm run typecheck"
      expect: "exit 0"
  risk: LOW|MEDIUM|HIGH  # From tradeoff-analyzer
```

**Guidelines**:
- Acceptance + integration tests are specified in the plan; unit tests are left to worker discretion
- Commands must be reproducible (no interactive steps)
- HIGH risk TODOs must include rollback steps alongside verification
- If no mechanical verification is possible, mark as `manual: true` and require user opt-in

### Risk Tagging

Each TODO receives a risk tag from the tradeoff-analyzer:

| Risk | Meaning | Plan Requirements |
|------|---------|-------------------|
| LOW | Reversible, isolated | Standard verification |
| MEDIUM | Multiple files, API changes | Verify block + plan-reviewer scrutiny |
| HIGH | DB schema, auth, breaking API | Verify block + rollback steps + human approval before execution |

### Key Principles
- Worker sees only its own TODO (isolation)
- Orchestrator substitutes `${todo-N.outputs.field}`
- **Only Orchestrator commits to git** (Worker is prohibited)
- **TODO Final uses same Acceptance Criteria structure** (unified verification)

**TODO Final**:
- Type: `verification` (read-only, cannot modify files)
- Same categories: Functional, Static, Runtime
- Same Hook verification process
- Difference: scope is "entire project"

See `${baseDir}/templates/PLAN_TEMPLATE.md` for complete structure.

---

## Checklist Before Stopping

### Common (all modes)
- [ ] Plan file exists at `.dev/specs/{name}/PLAN.md`
- [ ] **Orchestrator Section** exists:
  - [ ] Task Flow
  - [ ] Dependency Graph
  - [ ] Commit Strategy
- [ ] **TODO Section** complete:
  - [ ] All TODOs have Type, Inputs, Outputs fields
  - [ ] All TODOs have Steps (checkbox) and Acceptance Criteria
  - [ ] All TODOs have Verify block (acceptance, commands, risk tag)
  - [ ] All TODOs have "Do not run git commands" in Must NOT do
  - [ ] HIGH risk TODOs include rollback steps
  - [ ] References populated from DRAFT's Agent Findings (incl. Documentation)
- [ ] **TODO Final: Verification** exists (type: verification, read-only, same Acceptance Criteria structure)
- [ ] Reviewer returned OKAY
- [ ] Draft file deleted

### Standard mode (additional, both interactive and autopilot)
- [ ] Draft completeness fully validated (Patterns, Commands, Documentation, External Dependencies, UX Review)
- [ ] Parallel analysis agents ran (gap-analyzer + tradeoff-analyzer + verification-planner, optionally external-researcher)
- [ ] Codex Strategic Synthesis attempted (Step 2.5) â€” result is one of: synthesis applied / SKIPPED / DEGRADED
- [ ] All HIGH risk decision_points presented to user and resolved

### Interactive mode (additional)
- [ ] User explicitly requested plan generation (standard+interactive only; quick auto-transitions)
- [ ] Decision Summary Checkpoint presented and confirmed by user
- [ ] Verification Summary Confirmation presented and confirmed by user (standard+interactive only)

### Quick mode (overrides)
- [ ] Only 2 exploration agents used (Explore Ã—2)
- [ ] Only tradeoff-lite analysis ran (1 agent)
- [ ] Interview step was skipped; Assumptions section populated
- [ ] Maximum 1 plan-reviewer round completed

### Autopilot mode (overrides)
- [ ] No `AskUserQuestion` calls made (except HIGH risk items)
- [ ] All autonomous decisions logged in Assumptions section
- [ ] Decision Summary logged to DRAFT (not presented to user)

---

## Example Flow

```
User: "/specify Add authentication to the API"

[Mode Selection]
- Auto-detect depth: "Add" â†’ standard
- Default interaction: interactive
- Resolved: {depth}=standard, {interaction}=interactive

[Interview Mode - Step 1: Initialize]
1. Classify: New Feature â†’ Pattern exploration strategy
2. Launch 4 parallel foreground agents (single message):
   - Explore #1: Find existing middleware patterns
   - Explore #2: Find project structure + commands
   - docs-researcher: Find ADRs, conventions, constraints
   - ux-reviewer: Evaluate UX impact
3. Create draft: .dev/specs/api-auth/DRAFT.md

[Interview Mode - Step 1.5: Exploration Summary]
4. Present summary to user:
   "Codebase exploration results:
    - Structure: src/middleware/, src/services/, src/routes/
    - Related patterns: logging.ts middleware pattern
    - Internal docs: ADR-003 JWT decision, CONTRIBUTING.md requires integration tests
    - Commands: npm test, npm run lint"
   â†’ User confirms context is correct

[Interview Mode - Step 1.1.5: Tech-Decision Proposal]
5. Detect: User request mentions "authentication" - potential tech choice needed
   Ask: "A technology choice seems needed. Shall we run a deep analysis?"
   - Yes, run analysis
   - No, proceed quickly
   â†’ User selects "Yes, run analysis"
6. Call: Skill("tech-decision", args="JWT vs Session for REST API authentication")
7. Update draft with tech-decision results

[Interview Mode - Step 2: Gather Requirements]
8. PROPOSE (based on exploration + tech-decision):
   "Based on tech-decision analysis, JWT is recommended for this use case.
    jsonwebtoken is already installed. src/middleware/logging.ts pattern works."
9. Record in User Decisions table

[Interview Mode - Step 3-4]
10. Update DRAFT continuously
11. Check: Critical Open Questions resolved? âœ“

User: "OK, make it a plan"

[Plan Generation Mode]
1. Validate draft completeness âœ“
2. Launch 4 parallel analysis agents:
   - gap-analyzer: missing reqs, AI pitfalls
   - tradeoff-analyzer: risk assessment, simpler alternatives
   - verification-planner: test infra, A-items vs H-items
   - external-researcher: (skipped - no migration/new lib)
2.5. Codex Strategic Synthesis:
   - Call codex-strategist with all 4 analysis results
   - Codex finds: 1 blind spot (missing rate limit on new endpoint)
   - Recommendation: add rate limit TODO before auth middleware
3. Present HIGH risk decision_points â†’ User selects option
4. Decision Summary Checkpoint:
   "User decisions: JWT, REST API
    Agent decisions: [MED] JSON response, [LOW] src/services/auth/
    Risk: HIGH 1 (approved), MED 3, LOW 5"
   â†’ User confirms
5. Write: .dev/specs/api-auth/PLAN.md (with Verify blocks + Verification Summary)
5.5. Present Verification Summary â†’ User confirms
6. Call: Task(plan-reviewer)
7. Reviewer says REJECT (semantic: missing rollback for DB change)
   â†’ Present rejection to user â†’ User selects "Apply suggested fix"
8. Edit plan, add rollback steps
9. Call plan-reviewer again
10. Reviewer says OKAY
11. Delete draft
12. Guide user to next steps: /open or /execute
```

### Quick Mode Example

```
User: "/specify --quick Fix typo in README header"

[Mode Selection]
- Flag: --quick â†’ {depth}=quick
- Default interaction for quick: autopilot
- Resolved: {depth}=quick, {interaction}=autopilot

[Interview Mode - Step 1: Initialize]
1. Classify: Bug Fix â†’ Reproduce â†’ Root cause â†’ Fix
2. â›” Quick: Launch 2 agents only:
   - Explore #1: Find README and related patterns
   - Explore #2: Find project commands
3. Create draft with Assumptions section populated

[Interview Mode - Step 1.5: Abbreviated Summary]
4. Log: "Patterns: README.md:1, Commands: npm run lint"
   ðŸ¤– Autopilot: No confirmation wait, proceed immediately

[Interview Mode - Step 2: SKIPPED (Quick)]
5. Assumptions populated: standard approach, minimal change

[Plan Generation - Auto-transition (after exploration + summary + assumptions)]
6. â›” Quick: tradeoff-lite only (1 agent)
7. â›” Quick + ðŸ¤– Autopilot: Decision Summary skipped
8. Write: .dev/specs/fix-readme/PLAN.md
9. â›” Quick: Verification Summary skipped
10. Call reviewer (1 round max)
11. Reviewer OKAY â†’ Delete draft
12. ðŸ¤– Autopilot: Print plan path, stop (no AskUser)
    "Plan ready: .dev/specs/fix-readme/PLAN.md"
```

---

## Next Steps (Guide User)

> **Mode Gate**:
> - ðŸ¤– **Autopilot**: Skip `AskUserQuestion`. Print the plan file location and stop.
>   ```
>   "Plan approved: .dev/specs/{name}/PLAN.md
>    Next: run /open or /execute to proceed."
>   ```

After plan approval, ask the user to select next step using `AskUserQuestion`:

```
AskUserQuestion(
  question: "Plan approved. Select the next step.",
  options: [
    { label: "/open", description: "Create Draft PR (get reviewer feedback first)" },
    { label: "/execute", description: "Start implementation immediately (on current branch)" },
    { label: "/worktree create {name}", description: "Work in isolated worktree (spec auto-moves)" }
  ]
)
```

**Based on user selection**:
- `/open` â†’ `Skill("open", args="{name}")`
- `/execute` â†’ `Skill("execute", args="{name}")`
- `/worktree create {name}` â†’ `Skill("worktree", args="create {name}")`, then guide user to run `/execute` in the new worktree
